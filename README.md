# Toyota Project-Data Wrangling Part I and Part II

This is python scripts to clean and analyzing crash data at 430 intersections in
Toyta city. The purpose is to identify and clean all the crash records and to prepare
the data for modelling using either R or GAUSS.


## Part I-
These instructions will get you a copy of the project up and running on your local machine for development and testing purposes. See deployment for notes on how to deploy the project on a live system.
* All scripts are located in the:
```
file 1_Cleaning_Toyota_Data.
```
* Where all these scripts are designed to claculate-aggregate the crash count based on the distance function that created.
* The data then created to reflect both the one obtained from privous-research
of the DataBase Calculation including speed and traffic volumes with the one current today we have.
* The dataset is pulled from both Crash-Records obtained from Toyota City and other resources.

## Part II-
These instructions will get you a copy of the project up and running on your local machine for development and testing purposes. See deployment for notes on how to deploy the project on a live system.
* All scripts are located in the:
```
file 2_Toyota_Survey_Cleaning
```
* The purpose is to cobmine an existed variables from different research with the one existed in the current research.

### Prerequisites
What things you need to install the software and how to install them
```
Using Python Anaconda in terminal-mac
```

## Python Version

I have used python 3.7.1 Ananconda on MacBook Pro and MacPro.
See the results:


## Authors

* **Ghasak Ibrahim** - *Initial work* -

## License
This project is licensed under the MIT License - see the [LICENSE.md](LICENSE.md) file for details
## Acknowledgments
* Learned this from several resources.

## Inspiration
Following similar project at:
* [1] ()
